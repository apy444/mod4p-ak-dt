{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical notebook - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Lending Club\n",
    "\n",
    "Lending Club is the world leader in p2p lending having issued over ($9 billion) dollars in loans since they began in 2007. They are growing at a rate in excess of (150% a year).\n",
    "\n",
    "source: https://www.lendacademy.com/lending-club-review/\n",
    "\n",
    "### How it Works\n",
    "\n",
    "Peer to peer lending at Lending Club is a very simple process. It begins with the borrower. They apply for a loan and if they meet certain criteria (such as a minimum 660 FICO score) their loan is added to Lending Club’s online platform. Investors can browse the loans on the platform and build a portfolio of loans. The minimum investment an investor can make is just $25 per loan. Each portion of a loan is called a note and smart investors build a portfolio of notes to spread their risk among many borrowers.\n",
    "\n",
    "Lending Club will perform some level of verification on every borrower. As this verification process is happening investors can be funding portions of the loans. If the borrower passes verification the loan is approved for investors and will be issued to the borrower if fully funded. If the borrower fails verification the loan will not be issued. It will be deleted from the platform and all money that had been invested will be returned to the respective investors.\n",
    "\n",
    "A loan can stay on the platform for up to 14 days. Most loans are funded much quicker than that and once funded the loan will be deleted from the platform. Approved borrowers will receive their money (less an origination fee) in just a couple of business days once funding is complete and then begin making payments within 30 days. These payments will be for principal plus interest on a standard amortization schedule.\n",
    "\n",
    "### Explanation of loan grades\n",
    "\n",
    "Lending Club categorizes borrowers into seven different loan grades: A through G. Within each loan grade there are five sub-grades meaning there are 35 total loan grades for borrowers from A1 down to G5. Where a borrower is graded depends on many factors the most important of which is the data held in the borrower’s credit report. The better credit history a borrower has the better their loan grade with the very best borrowers receiving an A1 grade, which carries the lowest interest rate.\n",
    "\n",
    "Lending Club will pull the latest credit report for every borrower and take the data held in that report and other factors such as loan amount and loan term to determine the interest rate. Lending Club provides more information on their Interest Rates and How We Set Them page on their site. Learn more about the Lending Club borrower experience in this video where I apply for a Lending Club loan.\n",
    "\n",
    "### What are the Risks?\n",
    "\n",
    "Every investor should consider the risks of an investment before committing their money.  Investing with p2p lending has a number of risks:\n",
    "\n",
    "**Borrower defaults** – the loans are unsecured so an investor has little recourse if the borrower decides not to pay. The annual default rate across all grades at Lending Club is around 6 or 7% with higher risk borrowers having a higher default rate.\n",
    "\n",
    "**Lending Club bankruptcy** – This is a much smaller risk today than it was several years ago because Lending Club is making money and has had an influx of cash with the recent IPO. But the risk will always be there. In the unlikely event of a bankruptcy, there is a backup loan servicer who will take over servicing the loans but there would likely be some disruption and investors could lose some principal.\n",
    "\n",
    "**Interest rate risk** – the loan terms are three or five years so during this time interest rates could increase substantially. If an FDIC insured investment is paying 6% it makes investing in a Lending Club loan at 7% not the best investment.\n",
    "\n",
    "**Poor loan diversification** – many new investors get caught in this trap. They do not take advantage of the \\\\$25 minimum investment. If you invest in 20 loans at \\\\$250 you are running a much higher risk than if you invest in 200 loans at \\\\$25. If you only have 20 loans one default could wipe out most of your gains.\n",
    "\n",
    "**Liquidity risk** – There is a secondary market on Lending Club where loans can be sold but if you need to liquidate your entire investment you will likely lose some principal in the process.\n",
    "\n",
    "**Market-wide event or recession** – While p2p lending has been around since the latest recession in 2008, the asset class still remains untested when platforms were originating significant volumes. In a recession, defaults will increase and thus will result in a decrease in investor returns.\n",
    "\n",
    "\n",
    "**This analysis focuses on borrower defaults and tries to identify a better classification**\n",
    "\n",
    "### Data source:\n",
    "\n",
    "https://www.lendingclub.com/info/download-data.action\n",
    "\n",
    "\n",
    "Data includes yearly consumer loans given out with information was available at the time of the application and payment information. \n",
    "\n",
    "They also provide a short description of the columns.\n",
    "\n",
    "This analysis is based on **LendingClub loan data from 2014.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# from loan_helper import data_cleaning functions\n",
    "from loan_helper import data_converting\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lath LendingClub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading excel\n",
    "description = pd.read_excel('LendingClub/LCDataDictionary.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading Lending Club loan data from 2014\n",
    "# data_lc = pd.read_csv('LendingClub/LoanStats3c_securev1.csv', low_memory=False, header=1)\n",
    "# data_lc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from zip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in Lending Club loan data from zip file\n",
    "from zipfile import ZipFile\n",
    "zip_file = ZipFile('LendingClub/LoanStats3c_securev1.csv.zip')\n",
    "data_lc = pd.read_csv(zip_file.open('LoanStats3c_securev1.csv'), low_memory=False, header=1)\n",
    "data_lc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lc.loan_amnt.isna().sum() #there are rows without loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed two rows with full NAN values\n",
    "data_lc = data_lc.loc[data_lc.loan_amnt.notnull()]\n",
    "data_lc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Feature selection and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1. Understanding the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In order to understand the columns we created a dataframe with column names, two examples, datatype, number of missing values, and the long description. The dataframe was exported to excel to make decision on columns. The result is stored in col_selection.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from loan_helper import column_description\n",
    "desc = column_description(data_lc, description) #column_description() is my own function to create this table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1) #this allows us to see the very long description, if exceeds 50 char\n",
    "desc.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "desc.to_excel('col_desc_2014.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2. First round feauture selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Originally the dataset contained **150 columns/features**. Features were reduced due to many reasons listet below:\n",
    "\n",
    "- Discarded columns which were holding **irrelevant** information:\n",
    "    - id, member_id, url, policy_code, application_type, annual_inc_joint, dti_joint, verification_status_joint, acc_now_delinque\n",
    "- Discarded columns which contained **redundant** information:\n",
    "    - funded_amnt, funded_amnt_inv (the difference is funded by LC itself), int_rate, sub_grade, title, fico_range_high, desc (given as purpose)\n",
    "- Discarded columns that contained **payment or collection** information (34 columns)\n",
    "- Discarded columns that contained information that were not available at the time of credit application, **future info**\n",
    "    - issue_d, pymnt_plan, initial_list_status, last_credit_pull_d, last_fico_range_high, last_fico_range_low\n",
    "- Discarded features that require **too much data processing**\n",
    "    - emp_title (due to the free format), zip_code (there is a state instead)\n",
    "- Discarded columns with **only missing values** (30 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_selection = pd.read_excel('col_selection_2014.xlsx')\n",
    "col_selection.Cause.value_counts() #these are the different causes to discard columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_lc.application_type.unique() #there are only individual applications, no joint applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#the difference between low and high fico scores are a fix number, it is enough to keep only one of them\n",
    "(data_lc.fico_range_high - data_lc.fico_range_low).value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(data_lc.emp_title.unique()) #number of different values given as employment title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(data_lc.zip_code.unique()) #number of different values given to the zip_code (categorycal value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sum(data_lc.isna().sum() == len(data_lc)) #number of columns with missing values, 1 of them is ovelapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#col_selection.loc[col_selection.nan_counts == 235629, ['col_name', 'nan_counts']] #columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_col = col_selection.loc[col_selection.Decision == 'keep', 'col_name'].to_list()\n",
    "len(selected_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = data_lc.loc[:, selected_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "# sns.set_palette(sns.light_palette((360, 90, 50)))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "fig = plt.figure()\n",
    "sns.distplot(dataset.loan_amnt, bins=7, kde=False)\n",
    "plt.xlabel('loan amount');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(dataset.term)\n",
    "sns.lmplot(x='term', y='loan_amnt', hue='loan_status', data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='dti', y='loan_amnt', hue='loan_status', data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Converting data types\n",
    "\n",
    "- **emp_length** column was converted to numeric\n",
    "- **earliest_cr_line** date was converted to numeric (years)\n",
    "- **revol_util** (revolving utilization) was converted to numeric\n",
    "- creating **regions from state**, state column was removed\n",
    "- reduce categories of loan purpose by aggregation of close categories\n",
    "    - filled nan values with 0 in four columns (mths_since_recent_bc_dlq,mths_since_recent_revol_delinq,\n",
    "emp_length, mo_sin_old_il_acct)\n",
    "\n",
    "The above transformations do not impact dataleakage and can be done before train - test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_converting(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determing the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_term = pd.DataFrame(dataset.loan_status.value_counts())\n",
    "df_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meaning of the categories\n",
    "<b>Fully paid:</b> Loan has been fully repaid, either at the expiration of the 3- or 5-year year term or as a result of a prepayment.\n",
    "\n",
    "<b>Current:</b> Loan is up to date on all outstanding payments. \n",
    "\n",
    "<b>In Grace Period:</b> Loan is past due but within the 15-day grace period. \n",
    "\n",
    "<b>Late (16-30):</b> Loan has not been current for 16 to 30 days. Learn more about the tools LendingClub has to deal with delinquent borrowers.\n",
    "\n",
    "<b>Late (31-120):</b> Loan has not been current for 31 to 120 days. Learn more about the tools LendingClub has to deal with delinquent borrowers.\n",
    "\n",
    "<b>Default:</b> Loan has not been current for an extended period of time. Learn more about the difference between “default” and “charge off”.\n",
    "\n",
    "<b>Charged Off:</b> Loan for which there is no longer a reasonable expectation of further payments. Upon Charge Off, the remaining principal balance of the Note is deducted from the account balance. Learn more about the difference between “default” and “charge off”.\n",
    "\n",
    "Sosurce: https://help.lendingclub.com/hc/en-us/articles/215488038-What-do-the-different-Note-statuses-mean-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(columns=dataset['loan_status'], index=dataset['term'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to ignore the 'gray' categories, where there might chance to the recovery of the loan. The 'Current' category contains the 60 months term loans, removing them would panalize the long term loans by increasing the default rate within this category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select default categories:\n",
    "dataset.loc[dataset.loan_status == 'Fully Paid', 'default'] = 0\n",
    "dataset.loc[dataset.loan_status == 'Charged Off', 'default'] = 1\n",
    "dataset.loc[dataset.loan_status == 'Current', 'default'] = 0\n",
    "#dropped the rows where the loan status was different\n",
    "dataset = dataset.loc[dataset.default.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove loan_status, default replace it\n",
    "dataset = dataset.drop(columns='loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index()\n",
    "dataset = dataset.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_palette = [\"#8c8c8c\", \"#e54632\"]\n",
    "\n",
    "fig1 = plt.figure(figsize=(5,5))\n",
    "sns.countplot(x = 'default', data=dataset, palette=my_palette, )\n",
    "ax = plt.gca()\n",
    "plt.title('Target categories\\n', fontsize=16)\n",
    "ax.set_xticklabels(['Non-default', 'Default'])\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig1.savefig('Target_var');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feats = dataset.columns.to_list()\n",
    "x_feats.remove('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset.corr()\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(corr);\n",
    "# corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = []\n",
    "for i in range(corr.shape[1]):\n",
    "    for j in range(i+1, corr.shape[1]):\n",
    "        if corr.iat[i,j]>0.8:\n",
    "            corr_df.append([corr.index[i], corr.columns[j], corr.iat[i,j]])\n",
    "corr_df = pd.DataFrame(corr_df, columns = ['col_name1','col_name2', 'r_square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_col = ['installment', 'mo_sin_old_rev_tl_op', 'num_sats', 'revol_bal', 'bc_util', 'num_bc_tl',\n",
    "             'avg_cur_bal', 'total_bc_limit', 'num_actv_bc_tl', 'num_rev_tl_bal_gt_0', 'total_bal_ex_mort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_columns = list(set(corr_df.col_name1.unique()) | set(corr_df.col_name2.unique()))\n",
    "corr_columns.sort()\n",
    "corr2 = dataset.loc[:,corr_columns].corr()\n",
    "fig2 = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "plt.title('Feature correlation heatmap\\n', fontsize = 24)\n",
    "sns.heatmap(corr2)\n",
    "fig2.savefig('Feature_corr2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_feats.remove(col) for col in remove_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(dataset[x_feats], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Stratify=y' provide us the same ratio in the target variable then it was in the original dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, stratify=y) #25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further datacleaning separately for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- annual_inc: in case of annual income we had to handle extreme values (there are many strategies, we were choosing truncating the extreme values to the value of the 99 quantile)\n",
    "- imputing median values in place of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='median', copy=True, fill_value=None)\n",
    "imp.fit(X_train)  \n",
    "\n",
    "X_train_imp = imp.transform(X_train)      \n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_trunc = X_train.annual_inc.quantile(q=0.99)\n",
    "income_trunc\n",
    "\n",
    "b_train = X_train_imp > income_trunc\n",
    "b_test = X_test_imp > income_trunc\n",
    "\n",
    "X_train_imp[b_train] = income_trunc\n",
    "X_test_imp[b_test] = income_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train_imp[:,3])\n",
    "plt.title('Annual income');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most standard scaling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_imp)\n",
    "X_train_scaled = scaler.transform(X_train_imp)\n",
    "X_test_scaled = scaler.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: Increasing predictibility of loan defaults from actual default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximize the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(y_train, y_probability):\n",
    "    '''\n",
    "    inputs: y_train values and from the trained model the y probabilities for default\n",
    "    output: maximized F1 score, cut-off and the corresponding y_hat\n",
    "    '''\n",
    "    y = 0\n",
    "    F1_score = 0\n",
    "    cut_off = 0\n",
    "    for cutoff in np.linspace(0,1,101):\n",
    "        y_hat = (y_probability > cutoff) * 1\n",
    "        f1 = f1_score(y_train, y_hat)\n",
    "        if f1> F1_score:\n",
    "            F1_score = f1\n",
    "            cut_off = cutoff\n",
    "            y = y_hat\n",
    "    \n",
    "    print('Recall:', recall_score(y_train, y))\n",
    "    print('Precision:', precision_score(y_train, y))\n",
    "    print('F1_score:', F1_score)\n",
    "    print('Cut_off:', cut_off)\n",
    "    \n",
    "    conf_matrix = pd.DataFrame(confusion_matrix(y_train, y),\n",
    "                                    index=['actual 0', 'actual 1'],\n",
    "                                    columns=['predicted 0', 'predicted 1'])\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Selection - Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Modeling without imbalance strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Baseline: vanilla logistic regression (w/o imbalance strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_vanilla = LogisticRegression(C=1e9, solver='liblinear', max_iter=200)\n",
    "\n",
    "model_vanilla = logreg_vanilla.fit(X_train_scaled, y_train)\n",
    "y_probability = model_vanilla.predict_proba(X_train_scaled)[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, t = precision_recall_curve(y_train, model_vanilla.decision_function(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "plt.step(r, p, color='b', alpha=0.4, where='post')\n",
    "plt.fill_between(r, p, color='b', alpha=0.4, **step_kwargs)\n",
    "plt.xlabel('precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1])\n",
    "plt.title('Precision-Recall curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_train, y_probability)\n",
    "plt.plot(fpr_rt_lm, tpr_rt_lm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Lasso regression with different C values (w/o imbalance strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100, 1000, 10000]  # low value means high l1 penalty on coefficients\n",
    "\n",
    "for C in C_values:\n",
    "    logreg_l1 = LogisticRegression(C=C, penalty='l1',\n",
    "                                   solver='liblinear',\n",
    "                                   max_iter=200)\n",
    "    print('-'*40,f'\\nLasso regression with C = {C}')\n",
    "    model_l1 = logreg_l1.fit(X_train_scaled, y_train)\n",
    "    y_probability = model_l1.predict_proba(X_train_scaled)[:,1]\n",
    "    print(get_metric(y_train, y_probability))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Ridge regression with different C values (w/o imbalance strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100, 1000, 10000]  # low value means high l1 penalty on coefficients\n",
    "\n",
    "for C in C_values:\n",
    "    logreg_l2 = LogisticRegression(C=C, penalty='l2',\n",
    "                                   solver='newton-cg',\n",
    "                                   max_iter=200)\n",
    "    \n",
    "    print('-'*40,f'\\nRidge regression with C = {C}')\n",
    "    model_l2 = logreg_l2.fit(X_train_scaled, y_train)\n",
    "    y_probability = model_l2.predict_proba(X_train_scaled)[:,1]\n",
    "    print(get_metric(y_train, y_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Cross-Validation (w/o imbalance strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits= 5, random_state=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_vanilla = LogisticRegression(C=1e9,\n",
    "                                solver='newton-cg',\n",
    "                                max_iter=200)\n",
    "\n",
    "\n",
    "cv_vanilla = cross_validate(estimator=lr_vanilla,\n",
    "                            X=X_train_scaled, y=y_train,\n",
    "                            cv=cv,\n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = cross_val_predict(lr_vanilla, X_train_scaled, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = LogisticRegression(C=1,\n",
    "                            solver='newton-cg',\n",
    "                            penalty='l2',\n",
    "                            max_iter=200)\n",
    "\n",
    "cv_l2 = cross_validate(estimator=l2_reg, X=X_train_scaled, y=y_train,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1,\n",
    "                       return_estimator=True,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = cross_val_predict(l2_reg, X_train_scaled, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg = LogisticRegression(C=1,\n",
    "                            solver='saga',\n",
    "                            penalty='l1',\n",
    "                            max_iter=200)\n",
    "cv_l1 = cross_validate(estimator=l1_reg, X=X_train_scaled, y=y_train,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1,\n",
    "                       return_estimator=True,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = cross_val_predict(l1_reg, X_train_scaled, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Imbalance Strategy: Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train_rus).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train_ros).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Baseline Vanilla (imbalance strategy: undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_vanilla = LogisticRegression(C=1e9, solver='liblinear', max_iter=200)\n",
    "\n",
    "model_vanilla = logreg_vanilla.fit(X_train_rus, y_train_rus)\n",
    "y_probability = model_vanilla.predict_proba(X_train_scaled)[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Cross-validation (imbalance strategy: undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_vanilla = cross_validate(estimator=lr_vanilla,\n",
    "                            X=X_train_rus, y=y_train_rus,\n",
    "                            cv=cv,\n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "y_probability = cross_val_predict(lr_vanilla, X_train_rus, y_train_rus, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train_rus, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l2 = cross_validate(estimator=l2_reg, X=X_train_rus, y=y_train_rus,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1,\n",
    "                       return_estimator=True,\n",
    "                       return_train_score=True)\n",
    "y_probability = cross_val_predict(l2_reg, X_train_rus, y_train_rus, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train_rus, y_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l2 = cross_validate(estimator=l2_reg, X=X_train_scaled, y=y_train,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1,\n",
    "                       return_estimator=True,\n",
    "                       return_train_score=True)\n",
    "y_probability = cross_val_predict(l2_reg, X_train_rus, y_train_rus, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train_rus, y_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_train_rus, y_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_train_rus, y_probability)\n",
    "plt.plot(fpr_rt_lm, tpr_rt_lm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. IMBALANCE STRATEGY: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts()) #Previous original class distribution\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train_scaled, y_train) \n",
    "print(pd.Series(y_train_smote).value_counts()) #Preview synthetic sample class distributi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Baseline Vanilla (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla regression\n",
    "logreg_vanilla = LogisticRegression(C=1e9, solver='liblinear', max_iter=200)\n",
    "\n",
    "model_vanilla = logreg_vanilla.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = model_vanilla.predict_proba(X_train_scaled)[:,1]\n",
    "\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is our selected model, now we test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = model_vanilla_balance.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "get_metric(y_test, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_balance, r_balance, t_balance = precision_recall_curve(y_train, model_vanilla_balance.decision_function(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(13,6))\n",
    "\n",
    "step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "\n",
    "\n",
    "axs[0].fill_between(r, p, color='#8c8c8c', alpha=0.4, **step_kwargs)\n",
    "axs[0].set(title='Imbalance Precision-Recall Curve', xlabel='Recall', ylabel='Precision', xlim=(0.0, 1), ylim=(0.0, 1.05))\n",
    "\n",
    "axs[1].fill_between(r_balance, p_balance, color='r', alpha=0.4, **step_kwargs)\n",
    "axs[1].set(title='Balanced Precision-Recall Curve', xlabel='Recall', ylabel='Precision', xlim=(0.0, 1), ylim=(0.0, 1.05))\n",
    "# fig.savefig('Precision-recall curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  B) Lasso regression with different C values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01]  # low value means high l1 penalty on coefficients\n",
    "\n",
    "for C in C_values:\n",
    "    logreg_l1 = LogisticRegression(C=C, penalty='l1',\n",
    "                                   solver='liblinear',\n",
    "                                   max_iter=200)\n",
    "    print('-'*40,f'\\nLasso regression with C = {C}')\n",
    "    model_l1 = logreg_l1.fit(X_train_smote, y_train_smote)\n",
    "    y_probability = model_l1.predict_proba(X_train_scaled)[:,1]\n",
    "    get_metric(y_train, y_probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Ridge regression with different C values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01]  # low value means high l1 penalty on coefficients\n",
    "\n",
    "for C in C_values:\n",
    "    logreg_l2 = LogisticRegression(C=C, penalty='l2',\n",
    "                                   solver='newton-cg',\n",
    "                                   max_iter=200)\n",
    "    \n",
    "    print('-'*40,f'\\nRidge regression with C = {C}')\n",
    "    model_l2 = logreg_l2.fit(X_train_smote, y_train_smote)\n",
    "    y_probability = model_l2.predict_proba(X_train_scaled)[:,1]\n",
    "    get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits= 5, random_state=1000, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_vanilla = LogisticRegression(C=1e9,\n",
    "                                solver='newton-cg',\n",
    "                                max_iter=200)\n",
    "\n",
    "\n",
    "cv_vanilla = cross_validate(estimator=lr_vanilla,\n",
    "                            X=X_train_smote, y=y_train_smote,\n",
    "                            cv=cv,\n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = cross_val_predict(lr_vanilla, X_train_scaled, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = LogisticRegression(C=1,\n",
    "                            solver='newton-cg',\n",
    "                            penalty='l2',\n",
    "                            max_iter=200)\n",
    "\n",
    "cv_l2 = cross_validate(estimator=l2_reg, X=X_train_smote, y=y_train_smote,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1,\n",
    "                       return_estimator=True,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = cross_val_predict(l2_reg, X_train_scaled, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg = LogisticRegression(C=1,\n",
    "                            solver='saga',\n",
    "                            penalty='l1',\n",
    "                            max_iter=200)\n",
    "cv_l1 = cross_validate(estimator=l1_reg, X=X_train_smote, y=y_train_smote,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1,\n",
    "                       return_estimator=True,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = cross_val_predict(l1_reg, X_train_scaled, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "get_metric(y_train, y_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
